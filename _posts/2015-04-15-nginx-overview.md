---
layout: post
category: nginx
title: 为什么要折腾nginx
tags: nginx 高并发
---

&emsp;&emsp;现在很多涉及到大规模、高并发访问的Server，基本都是使用nginx作为反向代理服务器，进行网络请求的接收、分发以及缓存。特地问了下百度在线广告的师兄，它们的backend server也是使用的nginx。随着这一两年做的东西逐渐增多，也逐渐找到自己的兴趣，并不是Data Mining抑或Machine Learning，而在于与App相关的一些backend Server的开发，即涉及一些网络优化以及高并发的处理。

&emsp;&emsp;下个月需要做一个Server相关的项目，而也一直有意华商韬略的Server进行优化而还没行动。计划接下来的时间，先在台式机搭一个nginx的反向代理Server环境，将华商韬略的数据库进行部署，将数据处理的Server由Apache换成Tornado，并在Server做一些数据的Cache，提高CRUD的效率。之后将环境分别迁移到aws以及阿里云。一来，为下面的项目做好准备，二来，继续翻新华商韬略的iOS客户端。涉及大规模方面的问题，有必要发信问问老罗。

<!--more-->

### 1. 反向代理(Reverse Proxy):

&emsp;&emsp;使用代理服务器接受Internet的连接请求，将请求转发给内部网络的服务器，并将从内部服务器得到的结果返回给Internet上请求连接的客户端。因此对于Client看起来，反向代理服务器就是其能够看到的Server。使用反向代理的好处很多。

&emsp;&emsp;反向代理与正向代理的区别，主要相对于Client来说，如果Nginx就是其目的服务器，而不是Nginx隐藏的数据服务器，则Nginx是反向代理；如果对于Client来说，Nginx并不是目的服务器，只是作为一个转发请求的桥梁，而其为正向代理。对于正向代理服务器，Client需要进行相应的设置，即知道代理服务器的IP以及端口；而对于反向代理服务器，该服务器即是其目标服务器，不需要进行相应的设置。

&emsp;&emsp;反向代理服务器可以搭成集群，用户访问不同的资源服务器B时，让不同代理服务器Z(x)去应答不同用户，发送给不同用户不同的资源。因为不同的Z(x)可以做不同的Cache，而并不需要每次都像B发请求，特别是一些静态数据，如果这些反向代理服务器可以和用户x来自同一网络，则x对B的访问，就能得到高质量的速度，这也是CDN的核心技术。 


* 隔绝了内部真正进行数据处理的服务器，任何来自Internet的请求都必须经过反向代理，保障了安全性；
* 可以在反向代理服务器上缓存真实Web服务器的某些静态资源，减轻真实Web服务器的负载压力，而将静态资源与动态资源分开存储的方式，也有利于数据的分批返回，优化前端的页面加载，不至于在等待数据库返回的时候，前端出现长时间的空白；
* 可以使用RP充当负载均衡服务器，分发请求，平衡集群中各个服务器的压力；
* 相比于Apache/IIS，Nginx的运行速度更快、系统资源消耗更低，，处理并发请求的能力也更强；

<figure>
	<img src="http://mhs-blog.qiniudn.com/server_arch.jpg" alt="">
</figure>

#### 1.1 Nginx核心特点

* 跨平台，可以在大多数Unix like OS编译运行
* 配置简单
* 非阻塞、高并发连接：使用最新的epoll模型，数据复制时，磁盘I/O第一阶段非阻塞，能支撑5万左右的并发连接，实际生产环境中2~3万并发连接数
* 事件驱动：通信机制使用epoll模型，支持更大的并发连接
* Master/Worker结构
* 处理大并发的请求内存消耗小，3万并发连接，开启10个Nginx进程，消耗150M内存作用
* 内置健康检查功能，后台Web服务器宕机不影响前端访问
* 支持GZIP压缩，可以添加浏览器本地缓存的Header头
* 稳定性高，这也是反向代理普遍的特点


#### 1.2 异步非阻塞的良好机制

* 一个Web请求：建立连接 -> 接收数据 -> 发送数据，系统底层看来，都是数据的读写；
* 阻塞调用：读写事件没有准备好时，只能等待，即请求会被耽搁；
* 非阻塞：读写事件没有准备好，事件马上返回，请求定时检查事件是否准备好，即轮询。在时间间隔，可以进行其他的处理，但这样会带来很大的请求事件切换开销；
* 异步非阻塞：可以同时监控多个事件，阻塞调用，设置超时时间。对于epoll模型来说，事件没有准备好，放入epoll队列，事件准备好了，才去处理。epoll队列的存在，提供了处理高并发的能力。线程只有一个，能够同时处理的请求也只有一个，只是可以通过在请求间不断的切换，即循环处理多个准备好的事件，实现了并发；
* Nginx异步非阻塞与多线程方式相比的优势，不需要创建线程，每个请求占用内存小，不存在上下文切换。事实上，上下文切换的时间代价，还是很大的。而对于IIS服务器来说，会为每个请求创建一个工作线程，线程带来的内存占用非常大，上下文切换的CPU开销很大，自然产生性能瓶颈。而Nginx的轻量级，也就体现在单线程基于epoll队列的异步非阻塞机制。


#### 1.3 Nginx进程模型

&emsp;&emsp;一个master进程，生成一个或者多个worker进程，将原来串行的逻辑并行化，并将逻辑拆分成很多独立模块并行执行，Master组件主要进行逻辑拆分，将每个独立部分下发到多个Worker，同时维护Worker队列，Worker主要进行逻辑计算，并将结果返回Master	

<figure>
	<img src="http://mhs-blog.qiniudn.com/2015_04_15.png" alt="">
</figure> 